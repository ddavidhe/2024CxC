{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit #for data preprocessing and crass validating \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from statistics import mean\n",
    "from hyperopt import Trials, hp, fmin, tpe, STATUS_OK, space_eval #for hyperparameter tuning and minimizing\n",
    "\n",
    "from cyclic_boosting.pipelines import pipeline_CBClassifier\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "\n",
    "import seaborn as sns \n",
    "\n",
    "from scipy.stats import boxcox \n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "import joblib\n",
    "from tqdm import tqdm \n",
    "\n",
    "import swifter\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize()\n",
    "modelDict = joblib.load('modelDict.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('preprocessed_lstm.csv')\n",
    "building_id = pd.read_csv('devices.csv')\n",
    "test = pd.read_csv('test.csv', header = None)\n",
    "reading_types = pd.read_csv('reading_types.csv')\n",
    "\n",
    "predictions = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.columns = ['device_id', 'date', 'value_type_id']\n",
    "samples['date'] = pd.to_datetime(samples['date'])\n",
    "predictions = pd.merge(predictions, building_id, on='device_id', how='inner')\n",
    "predictions['date'] =  pd.to_datetime(predictions['date'])\n",
    "predictions['floored_date'] = predictions['date'].dt.floor('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048576 entries, 0 to 1048575\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   device_id      1048576 non-null  int64         \n",
      " 1   date           1048576 non-null  datetime64[ns]\n",
      " 2   value_type_id  1048576 non-null  int64         \n",
      " 3   building_id    1048576 non-null  int64         \n",
      " 4   floored_date   1048576 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(3)\n",
      "memory usage: 40.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1048576 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "predictions.info() \n",
    "progressBar = tqdm(total = len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(row):\n",
    "    type = row['value_type_id']\n",
    "    date = row['floored_date']\n",
    "    building = row['building_id']\n",
    "    model = modelDict[building][type - 1]\n",
    "\n",
    "    start_date = date  - timedelta(hours = 1)\n",
    "    inputs = samples[(samples['building_id'] == building)]\n",
    "    inputs = inputs[(inputs['date'] <= start_date)].head(1)\n",
    "\n",
    "\n",
    "    inputs = inputs.drop(['Unnamed: 0', 'building_id', 'date'], axis = 1)  \n",
    "\n",
    "    inputs = inputs[[str(type)]]\n",
    "\n",
    "    scaler = StandardScaler() \n",
    "    scaler = scaler.fit(inputs)\n",
    "    inputs_scaled = scaler.transform(inputs)\n",
    "\n",
    "    prediction = model.predict(inputs_scaled, verbose = 0)\n",
    "\n",
    "    pred = scaler.inverse_transform(prediction)[0, 0]\n",
    "\n",
    "    progressBar.update(1)\n",
    "\n",
    "    return pred #prob have to grab the value or smt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandarallel\\core.py\", line 158, in __call__\n    results = self.work_function(\n              ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandarallel\\data_types\\dataframe.py\", line 32, in work\n    return data.apply(\n           ^^^^^^^^^^^\n  File \"c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 10034, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n           ^^^^^^^^^^\n  File \"c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py\", line 837, in apply\n    return self.apply_standard()\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py\", line 965, in apply_standard\n    results, res_index = self.apply_series_generator()\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py\", line 981, in apply_series_generator\n    results[i] = self.func(v, *self.args, **self.kwargs)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Thomas\\AppData\\Local\\Temp\\ipykernel_33980\\546389936.py\", line 5, in get_predictions\nNameError: name 'modelDict' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandarallel\\core.py:444\u001b[0m, in \u001b[0;36mparallelize_with_pipe.<locals>.closure\u001b[1;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m worker_status \u001b[38;5;241m==\u001b[39m WorkerStatus\u001b[38;5;241m.\u001b[39mError:\n\u001b[0;32m    442\u001b[0m         progress_bars\u001b[38;5;241m.\u001b[39mset_error(worker_index)\n\u001b[1;32m--> 444\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mresults_promise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data_type\u001b[38;5;241m.\u001b[39mreduce(results, reduce_extra)\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modelDict' is not defined"
     ]
    }
   ],
   "source": [
    "predictions['value'] = predictions.parallel_apply(get_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.drop(['floored_date', 'building_id'], axis = 1)\n",
    "predictions.to_csv('predictions.csv', header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
